{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-27T15:28:06.859933Z",
     "start_time": "2025-05-27T15:28:06.797104Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from struct import pack\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the PINN model\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, num_hidden=128, num_layers=4):\n",
    "        super(PINN, self).__init__()\n",
    "        layers = []\n",
    "        # Input: (r, z, t)\n",
    "        layers.append(nn.Linear(3, num_hidden))\n",
    "        layers.append(nn.Tanh())\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(num_hidden, num_hidden))\n",
    "            layers.append(nn.Tanh())\n",
    "        # Output: T (temperature)\n",
    "        layers.append(nn.Linear(num_hidden, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Material properties and parameters (from the document)\n",
    "def thermal_conductivity(T):\n",
    "    Tm = 1944.0  # Melting temperature (K)\n",
    "    k = torch.where(T < Tm,\n",
    "                    22.5 + 8e-6 * (T - 650.0)**2,\n",
    "                    22.5 + 8e-6 * (Tm - 650.0)**2)\n",
    "    return k\n",
    "\n",
    "def heat_capacity(T):\n",
    "    Tm = 1944.0  # Melting temperature (K)\n",
    "    Tb = 3560.0  # Boiling temperature (K)\n",
    "    c = torch.where(T < Tm,\n",
    "                    4500.0 * (600.0 + 1.07e-5 * torch.abs(T - 500.0)**2.5),\n",
    "                    torch.where(T < Tb,\n",
    "                                950.0 * 4110.0,\n",
    "                                700.0 * 4110.0))\n",
    "    return c\n",
    "\n",
    "def smoothed_delta(T):\n",
    "    Tm = 1944.0  # Melting temperature (K)\n",
    "    delta_Tm = 40.0  # Width of melting interval (K)\n",
    "    return (1.0 / (delta_Tm * np.sqrt(2 * np.pi))) * torch.exp(-((T - Tm)**2) / (2 * delta_Tm**2))\n",
    "\n",
    "# Laser pulse intensity\n",
    "def laser_pulse(r, t):\n",
    "    t0 = 40e-6  # Pulse front duration (s)\n",
    "    r0 = 25e-6  # Beam radius (m)\n",
    "    P = 4000.0  # Power for 40 ÂµJ at f=100 kHz (W)\n",
    "    f = 100e3  # Pulse frequency (Hz)\n",
    "    Q0 = P / (f * np.pi * r0**2)  # Energy density per pulse\n",
    "    t_shifted = t - torch.floor(t * f) / f  # Time within one pulse period\n",
    "    q_p = torch.where(t_shifted >= 0,\n",
    "                      Q0 * (t_shifted / t0**2) * torch.exp(-t_shifted / t0) * torch.exp(-r**2 / r0**2),\n",
    "                      torch.tensor(0.0, device=t.device))\n",
    "    return q_p\n",
    "\n",
    "# Generate collocation points\n",
    "def generate_collocation_points(N_r=75, N_z=70, N_t=100):\n",
    "    r_max = 75e-6  # m\n",
    "    z_max = 40e-6  # m\n",
    "    t_max = 100e-6  # s\n",
    "    r = torch.linspace(0, r_max, N_r)\n",
    "    z = torch.linspace(0, z_max, N_z)\n",
    "    t = torch.linspace(0, t_max, N_t)\n",
    "    R, Z, T = torch.meshgrid(r, z, t, indexing='ij')\n",
    "    points = torch.stack([R.flatten(), Z.flatten(), T.flatten()], dim=1)\n",
    "    points.requires_grad_(True)\n",
    "    return points, r, z, t\n",
    "\n",
    "# Compute PDE residual\n",
    "def compute_pde_residual(model, points):\n",
    "    r = points[:, 0:1]\n",
    "    z = points[:, 1:2]\n",
    "    t = points[:, 2:3]\n",
    "    T = model(points)\n",
    "    \n",
    "    # Compute derivatives\n",
    "    T_t = torch.autograd.grad(T, t, grad_outputs=torch.ones_like(T), create_graph=True)[0]\n",
    "    T_r = torch.autograd.grad(T, r, grad_outputs=torch.ones_like(T), create_graph=True)[0]\n",
    "    T_z = torch.autograd.grad(T, z, grad_outputs=torch.ones_like(T), create_graph=True)[0]\n",
    "    T_rr = torch.autograd.grad(T_r, r, grad_outputs=torch.ones_like(T_r), create_graph=True)[0]\n",
    "    T_zz = torch.autograd.grad(T_z, z, grad_outputs=torch.ones_like(T_z), create_graph=True)[0]\n",
    "    \n",
    "    k = thermal_conductivity(T)\n",
    "    c = heat_capacity(T)\n",
    "    Lm = 1.43e9  # Latent heat (J/m^3)\n",
    "    delta = smoothed_delta(T)\n",
    "    \n",
    "    # PDE: (c + Lm * delta(T - Tm)) * T_t = (1/r) * d/dr(r * k * T_r) + d/dz(k * T_z)\n",
    "    term1 = (c + Lm * delta) * T_t\n",
    "    term2 = (1.0 / r) * (r * k * T_r) + k * T_rr + T_r * torch.autograd.grad(k, r, grad_outputs=torch.ones_like(k), create_graph=True)[0]\n",
    "    term3 = k * T_zz + T_z * torch.autograd.grad(k, z, grad_outputs=torch.ones_like(k), create_graph=True)[0]\n",
    "    residual = term1 - (term2 + term3)\n",
    "    return residual\n",
    "\n",
    "# Boundary and initial conditions\n",
    "def compute_bc_ic_loss(model, points, r, z, t):\n",
    "    r_max = 75e-6\n",
    "    z_max = 40e-6\n",
    "    T0 = 290.0  # Initial temperature (K)\n",
    "    R_coeff = 0.62  # Reflection coefficient\n",
    "    \n",
    "    # Initial condition: T(t=0) = T0\n",
    "    ic_points = points[points[:, 2] == 0]\n",
    "    if len(ic_points) > 0:\n",
    "        T_ic = model(ic_points)\n",
    "        ic_loss = torch.mean((T_ic - T0)**2)\n",
    "    else:\n",
    "        ic_loss = torch.tensor(0.0, device=points.device)\n",
    "    \n",
    "    # Boundary: dT/dr(r=0) = 0\n",
    "    bc_r0 = points[points[:, 0] == 0]\n",
    "    if len(bc_r0) > 0:\n",
    "        T_r0 = model(bc_r0)\n",
    "        T_r = torch.autograd.grad(T_r0, bc_r0, grad_outputs=torch.ones_like(T_r0), create_graph=True)[0][:, 0]\n",
    "        bc_r0_loss = torch.mean(T_r**2)\n",
    "    else:\n",
    "        bc_r0_loss = torch.tensor(0.0, device=points.device)\n",
    "    \n",
    "    # Boundary: dT/dr(r=r_max) = 0\n",
    "    bc_rmax = points[torch.isclose(points[:, 0], torch.tensor(r_max, device=points.device))]\n",
    "    if len(bc_rmax) > 0:\n",
    "        T_rmax = model(bc_rmax)\n",
    "        T_r = torch.autograd.grad(T_rmax, bc_rmax, grad_outputs=torch.ones_like(T_rmax), create_graph=True)[0][:, 0]\n",
    "        bc_rmax_loss = torch.mean(T_r**2)\n",
    "    else:\n",
    "        bc_rmax_loss = torch.tensor(0.0, device=points.device)\n",
    "    \n",
    "    # Boundary: -k * dT/dz(z=0) = (1-R) * q\n",
    "    bc_z0 = points[points[:, 1] == 0]\n",
    "    if len(bc_z0) > 0:\n",
    "        T_z0 = model(bc_z0)\n",
    "        T_z = torch.autograd.grad(T_z0, bc_z0, grad_outputs=torch.ones_like(T_z0), create_graph=True)[0][:, 1]\n",
    "        k = thermal_conductivity(T_z0)\n",
    "        q = laser_pulse(bc_z0[:, 0:1], bc_z0[:, 2:3])\n",
    "        bc_z0_loss = torch.mean((-k * T_z - (1 - R_coeff) * q)**2)\n",
    "    else:\n",
    "        bc_z0_loss = torch.tensor(0.0, device=points.device)\n",
    "    \n",
    "    # Boundary: dT/dz(z=z_max) = 0\n",
    "    bc_zmax = points[torch.isclose(points[:, 1], torch.tensor(z_max, device=points.device))]\n",
    "    if len(bc_zmax) > 0:\n",
    "        T_zmax = model(bc_zmax)\n",
    "        T_z = torch.autograd.grad(T_zmax, bc_zmax, grad_outputs=torch.ones_like(T_zmax), create_graph=True)[0][:, 1]\n",
    "        bc_zmax_loss = torch.mean(T_z**2)\n",
    "    else:\n",
    "        bc_zmax_loss = torch.tensor(0.0, device=points.device)\n",
    "    \n",
    "    return ic_loss + bc_r0_loss + bc_rmax_loss + bc_z0_loss + bc_zmax_loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, points, epochs=1000):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2000, gamma=0.5)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        pde_residual = compute_pde_residual(model, points)\n",
    "        pde_loss = torch.mean(pde_residual**2)\n",
    "        bc_ic_loss = compute_bc_ic_loss(model, points, r, z, t)\n",
    "        loss = pde_loss + 100.0 * bc_ic_loss  # Weight boundary conditions\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.6f}, PDE Loss: {pde_loss.item():.6f}, BC/IC Loss: {bc_ic_loss.item():.6f}\")\n",
    "\n",
    "# Save output in specified binary format\n",
    "def save_temperature_field(model, r, z, t, filename=\"output_Trd.bin\"):\n",
    "    model.eval()\n",
    "    Nr, Nz, Nt = len(r), len(z), len(t)\n",
    "    with open(filename, 'wb') as f:\n",
    "        for t_idx in range(Nt):\n",
    "            for k in range(Nz):\n",
    "                for p in range(Nr):\n",
    "                    point = torch.tensor([[r[p], z[k], t[t_idx]]], dtype=torch.float32)\n",
    "                    T = model(point).item()\n",
    "                    f.write(pack('d', T))\n",
    "    \n",
    "    # Save time points and surface temperatures\n",
    "    with open(\"output_ts.txt\", 'w') as f:\n",
    "        for t_idx in range(Nt):\n",
    "            point_center = torch.tensor([[0.0, 0.0, t[t_idx]]], dtype=torch.float32)\n",
    "            point_bottom = torch.tensor([[0.0, z[-1], t[t_idx]]], dtype=torch.float32)\n",
    "            T_center = model(point_center).item()\n",
    "            T_bottom = model(point_bottom).item()\n",
    "            f.write(f\"{t[t_idx]:.6e} {T_center:.6f} {T_bottom:.6f}\\n\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = PINN().to(device)\n",
    "    points, r, z, t = generate_collocation_points()\n",
    "    points = points.to(device)\n",
    "    r, z, t = r.to(device), z.to(device), t.to(device)\n",
    "    \n",
    "    # Train the model\n",
    "    train_pinn(model, points)\n",
    "        \n",
    "    # Save the results\n",
    "    save_temperature_field(model, r.cpu().numpy(), z.cpu().numpy(), t.cpu().numpy())"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 205\u001B[0m\n\u001B[0;32m    202\u001B[0m r, z, t \u001B[38;5;241m=\u001B[39m r\u001B[38;5;241m.\u001B[39mto(device), z\u001B[38;5;241m.\u001B[39mto(device), t\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    204\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m--> 205\u001B[0m \u001B[43mtrain_pinn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpoints\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;66;03m# Save the results\u001B[39;00m\n\u001B[0;32m    208\u001B[0m save_temperature_field(model, r\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy(), z\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy(), t\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "Cell \u001B[1;32mIn[3], line 165\u001B[0m, in \u001B[0;36mtrain_pinn\u001B[1;34m(model, points, epochs)\u001B[0m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m    164\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 165\u001B[0m     pde_residual \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_pde_residual\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpoints\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m     pde_loss \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(pde_residual\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    167\u001B[0m     bc_ic_loss \u001B[38;5;241m=\u001B[39m compute_bc_ic_loss(model, points, r, z, t)\n",
      "Cell \u001B[1;32mIn[3], line 85\u001B[0m, in \u001B[0;36mcompute_pde_residual\u001B[1;34m(model, points)\u001B[0m\n\u001B[0;32m     82\u001B[0m T \u001B[38;5;241m=\u001B[39m model(points)\n\u001B[0;32m     84\u001B[0m \u001B[38;5;66;03m# Compute derivatives\u001B[39;00m\n\u001B[1;32m---> 85\u001B[0m T_t \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mT\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     86\u001B[0m T_r \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mgrad(T, r, grad_outputs\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mones_like(T), create_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     87\u001B[0m T_z \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mgrad(T, z, grad_outputs\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mones_like(T), create_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:502\u001B[0m, in \u001B[0;36mgrad\u001B[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001B[0m\n\u001B[0;32m    498\u001B[0m     result \u001B[38;5;241m=\u001B[39m _vmap_internals\u001B[38;5;241m.\u001B[39m_vmap(vjp, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, allow_none_pass_through\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)(\n\u001B[0;32m    499\u001B[0m         grad_outputs_\n\u001B[0;32m    500\u001B[0m     )\n\u001B[0;32m    501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 502\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_outputs_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_unused\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    509\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m materialize_grads:\n\u001B[0;32m    512\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\n\u001B[0;32m    513\u001B[0m         result[i] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_tensor_like(inputs[i])\n\u001B[0;32m    514\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(inputs))\n\u001B[0;32m    515\u001B[0m     ):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\graph.py:824\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    822\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    823\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 824\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    826\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    827\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    828\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:09:59.519517Z",
     "start_time": "2025-05-27T15:09:59.517692Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dfc6f16e0a722c25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:10:01.678215Z",
     "start_time": "2025-05-27T15:10:01.675428Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "da7d5630e1a29438",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f660d17dab3cb44f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
